{
  "metadata": {
    "name": "data_ingestion",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 1. Businesses Dataset\n\n## Load DataFrame"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val dfBusiness \u003d spark.read.json(\"project/reviews/raw/meta-New_York.json\")\nz.show(dfBusiness)"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "dfBusiness.printSchema()\ndfBusiness.count()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Compute zip code from address and remove unnecessary columns"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "def getZip(address: String): Long \u003d {\n    if (address \u003d\u003d null) {\n        0L\n    } else {\n        val zipPattern \u003d\"\"\"(?:\\s+NY)\\s(\\d+)\"\"\".r\n        zipPattern.findFirstMatchIn(address) match {\n            case Some(matched) \u003d\u003e matched.group(1).toLong\n            case None \u003d\u003e 0L\n        }\n    }\n}\n\nspark.udf.register(\"getZip\", getZip(_))\n\ndfBusiness.createOrReplaceTempView(\"businesses\")\n\nval dfWithZip \u003d spark.sql(\"SELECT gmap_id, avg_rating, category, name, num_of_reviews, address, getZip(address) as zip FROM businesses\")\n\nz.show(dfWithZip.select(\"address\", \"zip\"))"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Get DataFrame of all NYC zipcodes, then clean it"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "var NYC_zipcodes \u003d spark.read\n    .option(\"header\", \"true\")\n    .option(\"mode\", \"DROPMALFORMED\")\n    .csv(\"project/reviews/raw/nyc_zipcodes.csv\")\n    \nNYC_zipcodes \u003d NYC_zipcodes.withColumn(\"ZIPCODES\", col(\"ZIPCODES\").cast(\"Long\"))\n\nz.show(NYC_zipcodes)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "  \n## Filter out businesses whose zipcodes don\u0027t lie within NYC"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val NYC_zipcodes_list \u003d NYC_zipcodes.rdd.flatMap(_.toSeq).collect()\n\nval df_NYC_only \u003d dfWithZip\n                    .drop(\"address\")\n                    .filter(col(\"zip\").isInCollection(NYC_zipcodes_list))\n\nz.show(df_NYC_only.select(\"zip\").describe())\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Ensure numeric fields don\u0027t have invalid values"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(df_NYC_only.select(\"avg_rating\", \"num_of_reviews\").describe())"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Save processed businesses"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "df_NYC_only.write.json(\"project/reviews/processed/nyc_businesses.json\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 2. Businesses Dataset\n\n## Load DataFrame"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val dfReviews \u003d spark.read.json(\"project/reviews/raw/review-New_York.json\")\nz.show(dfReviews)"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "dfReviews.printSchema()\ndfReviews.count()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Filter reviews to include only reviews from businesses located in NYC"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "var nyc_reviews_join \u003d dfReviews.join(df_NYC_only, Seq(\"gmap_id\"), \"inner\")\nz.show(nyc_reviews_join)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n## Convert the time column from timestamp into DateFormat data type"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val formattedDF \u003d nyc_reviews_join.withColumn(\n  \"datetime\",\n  to_timestamp(col(\"time\") / 1000)\n    .cast(\"timestamp\")\n    .as(\"datetime\")\n)\nz.show(formattedDF)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Remove unnecessary columns"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val nyc_reviews \u003d formattedDF.select(\"gmap_id\", \"rating\", \"datetime\", \"zip\")\nnyc_reviews.printSchema()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n## Ensure fields don’t have invalid values"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(nyc_reviews.describe())"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n## Find the minimum and maximum dates in the review dataset for NYC"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val minMaxDates \u003d formattedDF.agg(\n  min(\"datetime\").as(\"min_date\"),\n  max(\"datetime\").as(\"max_date\")\n)\n\nz.show(minMaxDates)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Save processed reviews"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "nyc_reviews.write.json(\"project/reviews/processed/nyc_reviews.json\")"
    }
  ]
}