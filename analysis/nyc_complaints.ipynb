{
  "metadata": {
    "name": "Project",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val filePath \u003d \"NYPD_Complaint_Data_Historic.csv\"\n\nval rawDF \u003d spark.read\n  .option(\"header\", \"true\")\n  .option(\"multiLine\", \"true\")\n  .option(\"inferSchema\", \"true\")\n  .option(\"escape\", \"\\\"\")\n  .csv(filePath)\n\nz.show(rawDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val baseDF \u003d rawDF.select(\n  \"cmplnt_num\",\n  \"cmplnt_fr_dt\",\n  \"cmplnt_fr_tm\",\n  \"cmplnt_to_dt\",\n  \"cmplnt_to_tm\",\n  \"rpt_dt\",\n  \"ofns_desc\",\n  \"law_cat_cd\",\n  \"boro_nm\",\n  \"susp_age_group\",\n  \"susp_race\",\n  \"susp_sex\",\n  \"latitude\",\n  \"longitude\",\n  \"vic_age_group\",\n  \"vic_race\",\n  \"vic_sex\",\n)\n\nbaseDF.cache().count"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(baseDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val baseDF1 \u003d baseDF.na.drop()"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(baseDF1)"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "baseDF1.printSchema"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "baseDF1.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.sql.functions._\nimport org.apache.spark.sql.types._\n\nval baseDF2 \u003d baseDF1.withColumn(\"cmplnt_fr_dt\", to_date(col(\"cmplnt_fr_dt\"), \"MM/dd/yyyy\")).\n                                withColumn(\"cmplnt_to_dt\",  to_date(col(\"cmplnt_fr_dt\"), \"MM/dd/yyyy\")).\n                                withColumn(\"rpt_dt\",  to_date(col(\"cmplnt_fr_dt\"), \"MM/dd/yyyy\"))\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(baseDF2)"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "baseDF2.printSchema"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val startDate \u003d \"2020-01-01\"\nval endDate \u003d \"2022-12-31\"\n\nval baseDF3 \u003d baseDF2.filter($\"rpt_dt\" \u003e\u003d startDate \u0026\u0026 $\"rpt_dt\" \u003c\u003d endDate)"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(baseDF3)"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "baseDF3.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val allowedAges \u003d Seq(\"\u003c18\", \"18-24\", \"25-44\", \"45-64\", \"65+\")\nval baseDF3_1 \u003d baseDF3.withColumn(\"susp_age_group\", when(col(\"susp_age_group\").isin(allowedAges: _*), col(\"susp_age_group\")).otherwise(null))\n                        .withColumn(\"vic_age_group\", when(col(\"vic_age_group\").isin(allowedAges: _*), col(\"vic_age_group\")).otherwise(null))\n\n//val baseDF4 \u003d baseDF3.filter(\n//  !baseDF3.columns.map(colName \u003d\u003e col(colName).isin(\"(null)\", \"UNKNOWN\")).reduce(_ || _)\n//)"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val columns \u003d baseDF3_1.columns\nval replacementValues \u003d Seq(\"(null)\", \"UNKNOWN\")\nval baseDF4 \u003d columns.foldLeft(baseDF3_1) { (tempDF, colName) \u003d\u003e\n  tempDF.withColumn(colName, when(col(colName).isin(replacementValues: _*), null).otherwise(col(colName)))\n}"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(baseDF4)"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "baseDF4.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(baseDF4.describe())"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.sql.types._\n\nval baseDF5 \u003d baseDF4.withColumn(\"latitude\", col(\"latitude\").cast(DoubleType))\n                .withColumn(\"longitude\", col(\"longitude\").cast(DoubleType))\n                .withColumn(\"cmplnt_fr_tm\", date_format(to_timestamp(col(\"cmplnt_fr_tm\"), \"HH:mm:ss\"), \"HH:mm:ss\"))\n                .withColumn(\"cmplnt_to_tm\", date_format(to_timestamp(col(\"cmplnt_to_tm\"), \"HH:mm:ss\"), \"HH:mm:ss\"))\n"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(baseDF5)"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "baseDF5.printSchema"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(baseDF5.select(\"boro_nm\").distinct())"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(baseDF5.select(\"vic_age_group\").distinct())"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(baseDF5.select(\"susp_race\").distinct())"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(baseDF5.select(\"ofns_desc\").distinct())"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(baseDF5.filter(col(\"longitude\").isNull))"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val filePath \u003d \"zipcodes.csv\"\n\nval zipcodes \u003d spark.read\n  .option(\"header\", \"true\")\n  .option(\"multiLine\", \"true\")\n  .option(\"inferSchema\", \"false\")\n  .option(\"escape\", \"\\\"\")\n  .csv(filePath)\n\nz.show(zipcodes)"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val zipcodesDF \u003d zipcodes.withColumn(\"LAT\", col(\"LAT\").cast(DoubleType))\n                         .withColumn(\"LNG\", col(\"LNG\").cast(DoubleType))"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val filePath \u003d \"nyc-zip-codes.csv\"\n\nval nycZipcodes \u003d spark.read\n  .option(\"header\", \"true\")\n  .option(\"multiLine\", \"true\")\n  .option(\"inferSchema\", \"false\")\n  .option(\"escape\", \"\\\"\")\n  .csv(filePath)\n  .select(\"ZipCode\")\n  .map(_.getString(0))\n  .collect()\n  .toList"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val newZipcodes \u003d zipcodesDF.filter(col(\"ZIP\").isin(nycZipcodes: _*)).collect()\nprint(newZipcodes, newZipcodes.length)"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.sql.DataFrame\nimport org.apache.spark.sql.functions.broadcast\nimport org.apache.spark.sql.functions.udf\n\ndef haversine(lat1: Double, lon1: Double, lat2: Double, lon2: Double): Double \u003d {\n    val latDistance \u003d Math.toRadians(lat1 - lat2)\n    val lngDistance \u003d Math.toRadians(lon1 - lon2)\n    val sinLat \u003d Math.sin(latDistance / 2)\n    val sinLng \u003d Math.sin(lngDistance / 2)\n    val a \u003d sinLat * sinLat +\n    (Math.cos(Math.toRadians(lat1)) *\n        Math.cos(Math.toRadians(lat2)) *\n        sinLng * sinLng)\n    val c \u003d 2 * Math.atan2(Math.sqrt(a), Math.sqrt(1 - a))\n    (6371 * c).toInt\n}\n\nval haversineUDF \u003d udf(haversine _)\n\nval newZipcodeBrod \u003d sc.broadcast(newZipcodes)\n\nval getNearestZipCode \u003d udf((lat1: Double, lon1: Double) \u003d\u003e {\n    var minDistance \u003d Double.MaxValue\n    var nearestZipCode \u003d \"\"\n\n    newZipcodeBrod.value.foreach { row \u003d\u003e\n        val lat2 \u003d row.getAs[Double](\"LAT\")\n        val lon2 \u003d row.getAs[Double](\"LNG\")\n        val distance \u003d haversine(lat1, lon1, lat2, lon2)\n        if (distance \u003c minDistance) {\n            minDistance \u003d distance\n            nearestZipCode \u003d row.getAs[String](\"ZIP\")\n        }\n    }\n    nearestZipCode\n})\n\nval result \u003d baseDF5.withColumn(\"zipcode\", getNearestZipCode(col(\"latitude\"), col(\"longitude\")))"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(result)"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val outputPath \u003d \"hdfs:///user/kn2359_nyu_edu/complaints\"\nresult.write.option(\"header\", \"true\").csv(outputPath)"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "print(result.count())"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val filePath \u003d \"complaints\"\n\nval mydf \u003d spark.read\n  .option(\"header\", \"true\")\n  .option(\"multiLine\", \"true\")\n  .option(\"inferSchema\", \"true\")\n  .option(\"escape\", \"\\\"\")\n  .csv(filePath)\n\nprint(mydf.count())"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(mydf.select(\"susp_age_group\").distinct())"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\nval stanleyPath \u003d \"/user/lsj3272_nyu_edu/shared/reviews/nyc_businesses.csv\"\n\nval stanleyDf \u003d  spark.read\n  .option(\"header\", \"true\")\n  .option(\"multiLine\", \"true\")\n  .option(\"inferSchema\", \"true\")\n  .option(\"escape\", \"\\\"\")\n  .csv(stanleyPath)"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val joinedDf \u003d mydf.join(stanleyDf, stanleyDf(\"zip\") \u003d\u003d\u003d mydf(\"zipcode\"))"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val category \u003d joinedDf.select(\"category\").withColumn(\"cats\",  explode(split(col(\"category\"), \".\")))\n                        .drop(\"category\")"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val catDF1 \u003d stanleyDf.select(\"category\").withColumn(\"cats\",  explode(split(col(\"category\"), \"\\\\.\"))).drop(\"category\")\nval catDF2 \u003d catDF1.groupBy(\"cats\").agg(count(\"cats\").alias(\"count\")).orderBy(desc(\"count\"))\nval dogDF3 \u003d catDF2.withColumn(\"cats\", lower(trim(col(\"cats\"))))\nz.show(catDF3)"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val mydf1 \u003d mydf.groupBy(\"zipcode\").agg(count(\"zipcode\").alias(\"cc_count\")).orderBy(desc(\"cc_count\"))\nz.show(mydf1)"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val joinedDf \u003d mydf1.join(stanleyDf, stanleyDf(\"zip\") \u003d\u003d\u003d mydf1(\"zipcode\"))"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val catDF1 \u003d joinedDf.withColumn(\"cats\",  explode(split(col(\"category\"), \"\\\\.\"))).drop(\"category\")\nval catDF2 \u003d catDF1.groupBy(\"cats\").agg(sum(\"cc_count\").alias(\"count\")).orderBy(desc(\"count\"))\nval catDF3 \u003d catDF2.withColumn(\"cats\", lower(trim(col(\"cats\"))))\nz.show(catDF3)"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "print(joinedDf.count())"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "print(mydf.count())"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "print(stanleyDf.count())"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val stanleyPath \u003d \"/user/lsj3272_nyu_edu/shared/reviews/nyc_businesses.csv\"\n\nval bussinessDF \u003d  spark.read\n  .option(\"header\", \"true\")\n  .option(\"multiLine\", \"true\")\n  .option(\"inferSchema\", \"true\")\n  .option(\"escape\", \"\\\"\")\n  .csv(stanleyPath)\n  \nval numBusinessDF \u003d bussinessDF.select(\"category\").withColumn(\"cats\",  explode(split(col(\"category\"), \"\\\\.\"))).drop(\"category\")\n                             .withColumn(\"cats\", lower(trim(col(\"cats\"))))\n                             .withColumn(\"cats\", regexp_replace(col(\"cats\"), \"(?i)(.*)(restaurant)(.*)\", \"restaurant\"))\n                             .withColumn(\"cats\", regexp_replace(col(\"cats\"), \"(?i)(.*)(salon)(.*)\", \"salon\"))\n                             .withColumn(\"cats\", regexp_replace(col(\"cats\"), \"cafe|coffee shop\", \"coffee shop\"))\n                             .groupBy(\"cats\").agg(count(\"cats\").alias(\"count\")).orderBy(desc(\"count\"))\n                             .filter(\"count \u003e\u003d 100\")\n\nz.show(numBusinessDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val filePath \u003d \"complaints\"\n\nval myDF \u003d spark.read\n  .option(\"header\", \"true\")\n  .option(\"multiLine\", \"true\")\n  .option(\"inferSchema\", \"true\")\n  .option(\"escape\", \"\\\"\")\n  .csv(filePath)\n\nval catsDF \u003d myDF\n           //.filter(\"law_cat_cd \u003d \u0027FELONY\u0027\")\n           .filter(\"law_cat_cd \u003d \u0027VIOLATION\u0027 OR law_cat_cd \u003d \u0027MISDEMEANOR\u0027\")\n           //.filter(\"law_cat_cd \u003d \u0027MISDEMEANOR\u0027\")\n           .groupBy(\"zipcode\").agg(count(\"zipcode\").alias(\"cc_count\")).orderBy(desc(\"cc_count\"))\n           .join(bussinessDF, bussinessDF(\"zip\") \u003d\u003d\u003d myDF(\"zipcode\"))\n           .withColumn(\"cats1\",  explode(split(col(\"category\"), \"\\\\.\"))).drop(\"category\")\n           .withColumn(\"cats1\", lower(trim(col(\"cats1\"))))\n           .withColumn(\"cats1\", regexp_replace(col(\"cats1\"), \"(?i)(.*)(restaurant)(.*)\", \"restaurant\"))\n           .withColumn(\"cats1\", regexp_replace(col(\"cats1\"), \"(?i)(.*)(salon)(.*)\", \"salon\"))\n           .groupBy(\"cats1\").agg(sum(\"cc_count\").alias(\"my_count\")).orderBy(desc(\"my_count\"))\n            \n           \nz.show(catsDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val finalDF1 \u003d catsDF.join(numBusinessDF, numBusinessDF(\"cats\") \u003d\u003d\u003d catsDF(\"cats1\")).drop(\"cats1\")\nz.show(finalDF1)"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val finalDF2 \u003d finalDF1.withColumn(\"crimes_per_cat\", col(\"my_count\")/col(\"count\")).drop(\"my_count\").orderBy(desc(\"crimes_per_cat\"))\nz.show(finalDF2)"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val filePath \u003d \"complaints\"\n\nval myDF \u003d spark.read\n  .option(\"header\", \"true\")\n  .option(\"multiLine\", \"true\")\n  .option(\"inferSchema\", \"true\")\n  .option(\"escape\", \"\\\"\")\n  .csv(filePath)\n\nval catsDF \u003d myDF\n           .groupBy(\"zipcode\", \"law_cat_cd\").agg(count(\"*\").alias(\"cc_count\")).orderBy(desc(\"cc_count\"))\n           .join(bussinessDF, bussinessDF(\"zip\") \u003d\u003d\u003d myDF(\"zipcode\"))\n           .withColumn(\"cats1\",  explode(split(col(\"category\"), \"\\\\.\"))).drop(\"category\")\n           .withColumn(\"cats1\", lower(trim(col(\"cats1\"))))\n           .withColumn(\"cats1\", regexp_replace(col(\"cats1\"), \"(?i)(.*)(restaurant)(.*)\", \"restaurant\"))\n           .withColumn(\"cats1\", regexp_replace(col(\"cats1\"), \"(?i)(.*)(salon)(.*)\", \"salon\"))\n           .groupBy(\"cats1\", \"law_cat_cd\").agg(sum(\"cc_count\").alias(\"num_complaints\")).orderBy(desc(\"num_complaints\"))\n\nz.show(catsDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val finalDF \u003d catsDF.join(numBusinessDF, numBusinessDF(\"cats\") \u003d\u003d\u003d catsDF(\"cats1\")).drop(\"cats1\")\n                     .withColumn(\"crimes_per_cat\", col(\"num_complaints\")/col(\"count\"))\n                     .withColumnRenamed(\"cats\", \"bussiness\")\n                     .withColumnRenamed(\"count\", \"crimes\")\n                     .orderBy(desc(\"crimes_per_cat\"))\nz.show(finalDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val outputPath \u003d \"/user/lsj3272_nyu_edu/shared/crime_categories.csv\"\nfinalDF.write.option(\"header\", \"true\").csv(outputPath)"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(myDF.select(\"cmplnt_num\", \"rpt_dt\", \"law_cat_cd\", \"boro_nm\", \"latitude\", \"longitude\", \"zipcode\"))"
    }
  ]
}